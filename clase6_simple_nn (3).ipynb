{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba8231",
   "metadata": {},
   "source": [
    "# Simple Neural Network, hagamoslo de cero!\n",
    "\n",
    "Recuerdo: definimos X como la matriz de entradas (features) e Y como la matriz de salidas esperadas (targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18710344",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0,0,1],\n",
    "    [1,1,1],\n",
    "    [1,0,1],\n",
    "    [0,1,1]\n",
    "])\n",
    "y = np.array([[0,1,1,0]]).T # La T es para que sea una matriz columna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137d8f9",
   "metadata": {},
   "source": [
    "Recordemos que la cuenta de una red neuronal simple es:\n",
    "$$\n",
    "z = \\sum_{i=0}^{n} w_{i} x_i = w_0 x_0 + w_1 x_1 + ... + w_n x_n\n",
    "$$\n",
    "A eso le aplicamos una función de activación, en este caso la sigmoide.\n",
    "Nos quedaría:\n",
    "$$\n",
    "output = \\sigma(\\sum_{i=0}^{n} w_{i} x_i)\n",
    "$$\n",
    "o de forma vectorial:\n",
    "$$\n",
    "\\text{output} = \\sigma\\!\\left(\n",
    "\\begin{bmatrix}\n",
    "w_1 & w_2 & \\cdots & w_n\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cbcdd",
   "metadata": {},
   "source": [
    "Ahora hagamos esta misma cuenta pero programando :)\n",
    "Definamos las cosas que nos faltan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02617196",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = None # Completar. Debería ser una vector de 3x1 con valores aleatorios. Usar función de numpy\n",
    "\n",
    "def sigmoid(x):\n",
    "    return None # Completar con la fórmula de la función sigmoide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce06cc",
   "metadata": {},
   "source": [
    "Ahora, creamos la función de forward propagation. Fijemonos que pasa cuando la usamos con los pesos random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, weights):\n",
    "    z = np.dot(X, weights)  # Producto punto entre X y los pesos\n",
    "    output = sigmoid(z)     # Aplicar la función sigmoide\n",
    "    return output\n",
    "\n",
    "output = forward_prop(X, weights)\n",
    "print(\"Output de la red neuronal con pesos random:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282d9f2",
   "metadata": {},
   "source": [
    "Claramente no tiene mucho sentido... Intentemos mejorarlo!\n",
    "\n",
    "Pasos para mejorar la red neuronal:\n",
    "- Definir una función de pérdida (loss function) para medir qué tan bien lo estamos haciendo.\n",
    "- Calculo la derivada de la función de pérdida.\n",
    "Esto es para saber en qué dirección ajustar los pesos (sumo o resto?)\n",
    "- Repito el proceso varias veces (epochs), ajustando los pesos en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193337f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ddc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pesos iniciales:\")\n",
    "print(weights)\n",
    "\n",
    "error = y - output\n",
    "print(\"\\n Error inicial:\")\n",
    "print(error)\n",
    "\n",
    "print(\"\\n Derivada de la función sigmoide aplicada al output:\")\n",
    "print(sigmoid_derivative(output))\n",
    "\n",
    "ajuste = error * sigmoid_derivative(output)\n",
    "print(\"\\n Ajuste a aplicar a los pesos:\")\n",
    "print(ajuste)\n",
    "\n",
    "weights += np.dot(X.T, ajuste)\n",
    "print(\"\\n Nuevos pesos después del ajuste:\")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ab901",
   "metadata": {},
   "source": [
    "**Consigna:** Hacer este mismo proceso de entrenamiento varias veces (si, es copiar y pegar el codigo de arriba en un for). Cuantas? El número de epochs.\n",
    "\n",
    "También guardarse los errores en una lista y graficarlas al final para ver como va mejorando la red neuronal!\n",
    "Recomendación: promediar los errores y tomarles valor absoluto para que no se cancelen entre sí. Esto es solo para graficar mejor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c59f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "errores = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pass\n",
    "    # Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570ed567",
   "metadata": {},
   "source": [
    "Veamos cómo quedaron los pesos finales\n",
    "\n",
    "Consigna: Escriban por que les parece que puede tener sentido que esos sean los pesos finales. (Miren el input y el output original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pesos finales después del entrenamiento:\")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff1df3",
   "metadata": {},
   "source": [
    "Les dejo un código para graficar la red neuronal con los pesos finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb92baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import itertools\n",
    "G = nx.DiGraph()\n",
    "layers = [[0, 1, 2], [3]]\n",
    "\n",
    "rels = list(itertools.product(*layers))\n",
    "#rels.append((3, 4))\n",
    "flatten = lambda l: [x for i in l for x in i]\n",
    "\n",
    "labels = {i: v for i, v in enumerate(X[1])}\n",
    "labels[3] = round(forward_prop(X[1], weights)[0], 3)\n",
    "#labels[4] = 0 if res < thresh else 1\n",
    "\n",
    "pos = {}\n",
    "m = max([len(l) for l in layers])\n",
    "for i, l in enumerate(layers):\n",
    "  for j, v in enumerate(l):\n",
    "    pos[v] = (i, len(l) - j)\n",
    "\n",
    "pos[3] = (pos[3][0], pos[1][1])\n",
    "#pos[4] = (pos[3][0] + 1, pos[1][1])\n",
    "\n",
    "weights_labels = {(ra, rb): \"{:0.3f}\".format(weights[i][0]) for i, (ra, rb) in enumerate(rels)}\n",
    "G.add_edges_from(rels)\n",
    "\n",
    "options = {\n",
    "    \"font_size\": 16,\n",
    "    \"node_size\": 3000,\n",
    "    \"node_color\": [(1, 1, 1, 1) for _ in range(len(labels))],\n",
    "    \"edgecolors\": \"black\",\n",
    "    \"linewidths\": 3,\n",
    "    \"width\": 3,\n",
    "    \"labels\": labels,\n",
    "    \"connectionstyle\": \"arc3, rad=0\",\n",
    "}\n",
    "\n",
    "nx.draw_networkx(G, pos, **options)\n",
    "\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G, pos,\n",
    "    edge_labels=weights_labels,\n",
    "    font_color='black',\n",
    "    font_size=16, \n",
    "    font_weight='bold'\n",
    ")\n",
    "\n",
    "plt.axis('off')\n",
    "ax = plt.gca()\n",
    "ax.margins(0.20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3cabd8",
   "metadata": {},
   "source": [
    "**Última consigna**: Prueben algunos ejemplos nuevos, que no estén en el dataset original, y vean qué predice la red neuronal "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
